INFO:mlagents_envs.environment:Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0
INFO:mlagents_envs.environment:Connected new brain: SoccerTwos?team=1
INFO:mlagents_envs.environment:Connected new brain: SoccerTwos?team=0
Traceback (most recent call last):
  File "c:\Users\nmone\OneDrive\Desktop\CS\soccer-twos-working\mappo-competitive-reinforcement\run_soccer_twos_main.py", line 429, in <module>
    trainer = create_trainer(env, agents, opponents, save_dir, state_size, action_size, use_PSRO=True, update_frequency=1500)
  File "c:\Users\nmone\OneDrive\Desktop\CS\soccer-twos-working\mappo-competitive-reinforcement\run_soccer_twos_main.py", line 170, in create_trainer
    trainer = PSRO(
  File "c:\Users\nmone\OneDrive\Desktop\CS\soccer-twos-working\mappo-competitive-reinforcement\run_soccer_twos_main.py", line 301, in __init__
    self.benchmark_opponents = (create_opponent(state_size, action_size, epoch=8500, agent_ix=0, benchmark = True), create_opponent(state_size, action_size, epoch=8500, agent_ix=1, benchmark=True))
  File "c:\Users\nmone\OneDrive\Desktop\CS\soccer-twos-working\mappo-competitive-reinforcement\run_soccer_twos_main.py", line 61, in create_opponent
    return Opponent(state_size, action_size, actor_fc1_units, actor_fc2_units, path)
  File "c:\Users\nmone\OneDrive\Desktop\CS\soccer-twos-working\mappo-competitive-reinforcement\mappo\ppo_model.py", line 31, in __init__
    self.actor.load_state_dict(torch.load(weights_path), strict=False)
  File "c:\Users\nmone\OneDrive\Desktop\CS\soccer-twos-working\s2env\lib\site-packages\torch\serialization.py", line 986, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "c:\Users\nmone\OneDrive\Desktop\CS\soccer-twos-working\s2env\lib\site-packages\torch\serialization.py", line 435, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "c:\Users\nmone\OneDrive\Desktop\CS\soccer-twos-working\s2env\lib\site-packages\torch\serialization.py", line 416, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'C:\\Users\\nmone\\OneDrive\\Desktop\\CS\\soccer-twos-working\\saved_files\\saved_files\\actor_agent_0_episode_8500.pth'
[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0
[INFO] Connected new brain: SoccerTwos?team=1
[INFO] Connected new brain: SoccerTwos?team=0
